{"name":"Zpeng","tagline":"Blog","body":"##Lua编译实践-词法分析：\r\n\r\n前言：\r\n编译实践系列将以lua的词法，语法和语意为标准，用C++实现lua的解释器，会采用编译原理中基本流程：\r\n词法分析 => 语法分析 => 抽象语法树(AST) => 语意分析(符号表) => 代码生成（字节码）。当然lua官方解释器采用边读入边生成代码没有所谓的AST。\r\n主要分成三部分：\r\n前端词法和语法分析；\r\n语意分析侧重在lua语言的特性(table, closure, coroutine, bind c/c++)特性的实现，会弱化符号检查；\r\nVirtual Machine和Garbage Collection；\r\n\r\n\r\n词法分析：\r\n先看一道常见的面试题：把字符串转换为整数（即实现atoi），如果考虑到实现基本功能（不含溢出处理），这并不难：依次读入字符取得对应的数字再乘以权重累加即可，正负数也只是加个前置判断而已。\r\n\r\n再给道题，判断一段字符串是否满足一下要求：只能以字母或下划线开始，其余部分数字、字母、下划线均可。我相信这个也不难，从头开始扫描字符串，if判断即可。\r\n\r\n如果再告诉你一条规则，以 ‘“’ 开头直到遇到 ‘”’结尾，或者以 单引号开头和结尾可判定为字符串常量。\r\n\r\n最后，增加判定是运算符（+ - * 、 % <= ...）和分隔符(; , ...)的规则，也就可以识别程序语言中的运算符和分割符了。只不过这里会用到一个小技巧，lua里存在 \".\", \"..\", \"...\" 当字符判定为\".\"时，会继续预读入下一个字符再判定， 如果第二个字符是\".\" 则拿到该字符，结果为\"..\"，继续这么处理第三个字符。可以将这个判断转化为查表。\r\n\r\n当完成这几个函数，那么需要考虑什么时候选择解析成数字，什么时候解析成字符串...，其核心在于预先看一两个字符做预判，决定走那条路，这里的预测可以采用标准流的peek, get, putback等函数完成，其基本框架如下：\r\n\r\n```C++\r\nwhile (true)\r\n{       \r\n        // init a single token recognise state\r\n        \r\n        char ch = GetNextChar();\r\n                \r\n        if (isdigit(ch))\r\n        {\r\n            tk = ProcessNumberState(ch);\r\n        }\r\n        else if (std::isalpha(ch) || ch == '_')\r\n        {\r\n            tk = ProcessIndentifyState(ch);\r\n        }\r\n        else if (ch == '\\'' || ch == '\"')\r\n        {\r\n            tk = ProcessStringState(ch);\r\n        }\r\n        else if (ch == '-' && PeekNextChar() == '-')\r\n        {\r\n            HandleComemnt(ch);\r\n            continue;\r\n        }\r\n        else if (m_dict.haveToken(std::string(1,ch)))\r\n        {\r\n            tk = ProcessOperatorAndDelim(ch);\r\n        }\r\n        else\r\n        {\r\n            m_currState = S_Fatal;\r\n            m_strErrReason = \"cannot find dispatch method\";\r\n        }\r\n}\r\n```\r\n[具体源码请参考scanner.cpp](https://github.com/pzhp/lua_interpretor/tree/master/lua_interpretor)\r\n\r\n既然故事这么简单，那么为什么编译原理类的书会讲正则文法，有限状态自动机（DFA，NFA），搞的那么复杂呢？简单所说，那是为了泛化，满足可配置性，将具体的解析规则提取出来，可以定制。以flex为例，它的工作方式非常类似awk：pattern{action}：\r\n```\r\n/* 规定DIGIT为0-9的数，如果规定[0-8]，那么9将无法被判定到数字里面 */\r\nDIGIT             ([0-9])\r\nHEX_DIGIT         ([0-9a-fA-F])\r\nHEX_INTEGER       (0[Xx]{HEX_DIGIT}+)\r\nINTEGER           ({DIGIT}+)\r\nEXPONENT          ([Ee][-+]?{INTEGER})\r\nDOUBLE            ({INTEGER}\".\"{DIGIT}*{EXPONENT}?)\r\nBEG_STRING        (\\\"[^\"\\n]*)\r\nSTRING            ({BEG_STRING}\\\")\r\nIDENTIFIER        ([a-zA-Z][a-zA-Z_0-9]*)\r\nOPERATOR          ([-+/*%=.,;!<>()[\\]{}])\r\nBEG_COMMENT       (\"/*\")\r\nEND_COMMENT       (\"*/\")\r\nSINGLE_COMMENT    (\"//\"[^\\n]*)\r\n\r\n/* -------------------- Constants ------------------------------ */\r\n\"true\"|\"false\"      { yylval.boolConstant = (yytext[0] == 't');\r\n                         return T_BoolConstant; }\r\n{INTEGER}           { yylval.integerConstant = strtol(yytext, NULL, 10);\r\n                         return T_IntConstant; }\r\n{HEX_INTEGER}       { yylval.integerConstant = strtol(yytext, NULL, 16);\r\n                         return T_IntConstant; }\r\n{DOUBLE}            { yylval.doubleConstant = atof(yytext);\r\n                         return T_DoubleConstant; }\r\n{STRING}            { yylval.stringConstant = _strdup(yytext); \r\n                         return T_StringConstant; }\r\n{BEG_STRING}        { ReportError::UntermString(&yylloc, yytext); }\r\n\r\n/* -------------------- Identifiers --------------------------- */\r\n{IDENTIFIER}        { if (strlen(yytext) > MaxIdentLen)\r\n                         ReportError::LongIdentifier(&yylloc, yytext);\r\n                       strncpy(yylval.identifier, yytext, MaxIdentLen);\r\n                       yylval.identifier[MaxIdentLen] = '\\0';\r\n                       return T_Identifier; }\r\n```\r\n[具体源码请参考scanner.l](https://github.com/pzhp/Decafe-Compiler)\r\n\r\n至此，前端词法分析的框架出来，\r\n\r\n（如果数字超过其类型溢出，gcc会怎么处理？ 默认情况是int，超出会给warning，并尝试向长整型转）","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}